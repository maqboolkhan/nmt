{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28602591-bd9f-467c-a015-11acf39a5665",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71e62732-00db-4b4e-8a3e-69be08de0fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import math\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import nmtDataset\n",
    "import helpers as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58b39d2b-bbf2-4235-ad90-af8ee6d59ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea59b269-3071-4785-9651-fe811872aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_params = {\n",
    "    \"batch_size\": 128,\n",
    "    \"num_epochs\": 10,\n",
    "\n",
    "    # Encoder parameters\n",
    "    \"encoder_embedding_size\": 512,\n",
    "    \"encoder_dropout\": 0.5,\n",
    "\n",
    "    # Decoder parameters\n",
    "    \"decoder_dropout\": 0.5,\n",
    "    \"decoder_embedding_size\": 512,\n",
    "\n",
    "    # Common parameters\n",
    "    \"hidden_size\": 512,\n",
    "    \"num_layers\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7daf9a0c-37b3-4dad-9d85-0c2ad4bdd89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = utils.Logger('logs/emd512-enc2-dec2-bilstm.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77f80e9c-9731-4b1c-b4f3-639e93958911",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        self.LSTM = nn.LSTM(embedding_dim, hidden_size, num_layers, dropout=dropout, bidirectional = True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Shape (embedding) --> [Sequence_length , batch_size , embedding dims]\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        \n",
    "        # ************** Multiplied by 2 because of bi-directional LSTM\n",
    "        # Shape --> (output) [Sequence_length , batch_size , hidden_size * 2]\n",
    "        # Shape --> (hs, cs) [num_layers * 2, batch_size size, hidden_size]\n",
    "        outputs, (hidden_state, cell_state) = self.LSTM(embedding)\n",
    "        \n",
    "        return hidden_state, cell_state\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, dropout, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "         # ************** Multiplying 2 because of bi-directional LSTM\n",
    "        self.LSTM = nn.LSTM(embedding_dim, hidden_size, num_layers * 2, dropout=dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x, hidden_state, cell_state):\n",
    "        # As we are not feeding whole sentence we will each token a time\n",
    "        # hence our sequence length would be just 1 however shape of x is batch_size\n",
    "        # to add sequence length we will unsequeeze it\n",
    "        # Shape (x) --> [batch_size] (see seq2seq model) so making it [1, batch_size]\n",
    "        x = x.unsqueeze(0)\n",
    "        \n",
    "        # Shape (embedded) --> (1, batch_size, embedding dims)\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        \n",
    "        # Shape (outputs) --> (1, 32, 1024) [1, batch_size , hidden_size]\n",
    "        # Shape (hs, cl) --> (2, 32, 1024)  [num_layers * 2, batch_size , hidden_size]\n",
    "        outputs, (hidden_state, cell_state) = self.LSTM(embedded, (hidden_state, cell_state))\n",
    "\n",
    "        # Shape (outputs) -->  (1, batch_size, hidden_size)\n",
    "        # Shape (outputs.squeeze(0)) -->  (batch_size, hidden_size)\n",
    "        # Shape (predictions) --> (batch_size, target_vocab_size)\n",
    "        predictions = self.fc(outputs.squeeze(0))\n",
    "        \n",
    "        return predictions, hidden_state, cell_state\n",
    "\n",
    "class SeqtoSeq(nn.Module):\n",
    "    def __init__(self, gen_params, target_vocab, device):\n",
    "        super(SeqtoSeq, self).__init__()\n",
    "\n",
    "        self.Encoder = Encoder(gen_params[\"input_size_encoder\"],\n",
    "                          gen_params[\"encoder_embedding_size\"],\n",
    "                          gen_params[\"hidden_size\"],\n",
    "                          gen_params[\"num_layers\"],\n",
    "                          gen_params[\"encoder_dropout\"]).to(device)\n",
    "\n",
    "        self.Decoder = Decoder(gen_params[\"input_size_decoder\"],\n",
    "                          gen_params[\"decoder_embedding_size\"],\n",
    "                          gen_params[\"hidden_size\"],\n",
    "                          gen_params[\"num_layers\"],\n",
    "                          gen_params[\"decoder_dropout\"],\n",
    "                          gen_params[\"output_size\"]).to(device)\n",
    "\n",
    "        self.target_vocab = target_vocab\n",
    "        self.device = device\n",
    "    \n",
    "    def forward(self, source, target, tfr=0.5):\n",
    "        # Shape -> (Sentence length, Batch_size)\n",
    "        batch_size = source.shape[1]\n",
    "\n",
    "        target_len = target.shape[0]  # Length of target sentences\n",
    "        target_vocab_size = len(self.target_vocab)\n",
    "        \n",
    "        # here we will store all the outputs\n",
    "        # so outputs is arrange in a way that sentences are in column and batch size is row and every element\n",
    "        # will consist of probability of each word from the vocab\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(self.device)\n",
    "\n",
    "        # Shape --> (hs, cs) (num_layers * 2, batch_size size, hidden_size) (contains encoder's hs, cs - context vectors)\n",
    "        hidden_state, cell_state = self.Encoder(source)\n",
    "\n",
    "        # Shape (target) -> (Sentence length, Batch_size)\n",
    "        # Shape (x) --> (batch_size)\n",
    "        x = target[0]  # First token (Trigger)\n",
    "        \n",
    "        for i in range(1, target_len):\n",
    "            # Shape (output) --> (batch_size, target_vocab_size)\n",
    "            # Shape (hs, cl) --> (num_layers * 2, batch_size , hidden_size)\n",
    "            output, hidden_state, cell_state = self.Decoder(x, hidden_state, cell_state)\n",
    "            outputs[i] = output\n",
    "            best_guess = output.argmax(1)  # 0th dimension is batch size, 1st dimension is word embedding\n",
    "            # Schedule sampling\n",
    "            x = target[\n",
    "                i] if random.random() < tfr else best_guess  # Either pass the next word correctly from the dataset\n",
    "            # or use the earlier predicted word\n",
    "\n",
    "        # Shape --> (sentence length, batch size, vocab size)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "772e5645-da1e-4ac6-9bd1-ab3e2ffb13f0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "nmtds_train = nmtDataset('datasets/Multi30k/', 'train')\n",
    "nmtds_valid = nmtDataset('datasets/Multi30k/', 'val', nmtds_train)\n",
    "nmtds_test = nmtDataset('datasets/Multi30k/', 'test', nmtds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73779a22-9baa-49d5-a298-13b1abe6d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(nmtds_train, batch_size=hyp_params['batch_size'], shuffle=True,\n",
    "                              collate_fn=lambda batch_size: utils.collate_fn(batch_size, device))\n",
    "\n",
    "valid_dataloader = DataLoader(nmtds_valid, batch_size=hyp_params['batch_size'], shuffle=True,\n",
    "                              collate_fn=lambda batch_size: utils.collate_fn(batch_size, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe2e61ed-c875-4a9a-9c57-60a9b82ee18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_params[\"input_size_encoder\"] = len(nmtds_train.src_vocab)\n",
    "hyp_params[\"input_size_decoder\"] = len(nmtds_train.trg_vocab)\n",
    "hyp_params[\"output_size\"] = len(nmtds_train.trg_vocab)\n",
    "\n",
    "model = SeqtoSeq(hyp_params, target_vocab=nmtds_train.trg_vocab, device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "pad_idx = nmtds_train.trg_vocab[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e89c4c12-8ad2-45cc-8d38-38a8e0af9e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [02:20<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 5.216370603586609, Eval loss: 4.687207579612732, patience: 1. Time 142.16274309158325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [02:20<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train loss: 4.598463703357176, Eval loss: 4.3513670563697815, patience: 1. Time 142.30233526229858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [02:22<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train loss: 4.173404616931461, Eval loss: 4.210356831550598, patience: 1. Time 144.33386492729187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [02:21<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train loss: 3.867253988324808, Eval loss: 4.019710153341293, patience: 1. Time 143.04434609413147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [02:21<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train loss: 3.6668072545055774, Eval loss: 3.990602344274521, patience: 1. Time 143.1064372062683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [02:20<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train loss: 3.5022870727572673, Eval loss: 3.9146927893161774, patience: 1. Time 142.4289939403534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [02:19<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train loss: 3.3620631736805784, Eval loss: 3.8330230712890625, patience: 1. Time 141.4496030807495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [02:20<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train loss: 3.241636825553121, Eval loss: 3.801970452070236, patience: 1. Time 141.77670741081238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [02:19<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train loss: 3.132763042323915, Eval loss: 3.7934650778770447, patience: 1. Time 141.08256220817566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [02:19<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 3.0410957599001307, Eval loss: 3.774424761533737, patience: 1. Time 141.120463848114\n"
     ]
    }
   ],
   "source": [
    "min_el = math.inf\n",
    "patience = 1\n",
    "best_model = {}\n",
    "best_epoch = 0\n",
    "\n",
    "epoch_loss = 0\n",
    "for epoch in range(hyp_params[\"num_epochs\"]):\n",
    "    start = time.time()\n",
    "    \n",
    "    epoch_loss = utils.train_model(model, train_dataloader, criterion, optimizer)\n",
    "    eval_loss = utils.evaluate_model(model, valid_dataloader, criterion)\n",
    "    \n",
    "    log.log(f\"Epoch: {epoch+1}, Train loss: {epoch_loss}, Eval loss: {eval_loss}, patience: {patience}. Time {time.time() - start}\")\n",
    "\n",
    "    \n",
    "    if eval_loss < min_el:\n",
    "        best_epoch = epoch+1\n",
    "        min_el = eval_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'eval_loss': min_el\n",
    "        }, 'model-bilstm.pt')\n",
    "        patience = 1\n",
    "    else:\n",
    "        patience += 1\n",
    "    \n",
    "    if patience == 10:\n",
    "        log.log(\"[STOPPING] Early stopping in action..\")\n",
    "        log.log(f\"Best epoch was {best_epoch} with {min_el} eval loss\")\n",
    "        break\n",
    "\n",
    "log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86a2bd3d-1eac-41c5-a4f3-57deb26f8237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_l = SeqtoSeq(hyp_params, target_vocab=nmtds_train.trg_vocab, device=device)\n",
    "model_l.load_state_dict(torch.load('model-bilstm.pt', map_location=device)[\"model_state_dict\"])\n",
    "model_l.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffb2c650-6614-4034-9b4a-12b828bb6a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:25<00:00, 39.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19580678641796112"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.bleu(model_l, nmtds_test, False, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a8fcfe-0047-4fc3-a6ed-fcc5a4d5d2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
