{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6979919-5368-481b-b0e6-393bb76c1d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b9c199bf-7a79-4bec-b443-ba7ff28fafe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(bi, inpu_dim):\n",
    "    inp_size, hidden_size, num_layers = inpu_dim, 1, 1\n",
    "    return nn.LSTM(inp_size, hidden_size, num_layers, bidirectional=bi)\n",
    "    \n",
    "\n",
    "def printer(inpt, o, h):\n",
    "    # [seq len, batch size, inp dimension]\n",
    "    print('Input: \\n')\n",
    "    print(inpt)\n",
    "    # [seq len, batch size, inp dimension * 2]\n",
    "    print('Output: \\n')\n",
    "    print(o)\n",
    "    # [num_layers * 2 , batch size, inp dimension]\n",
    "    print('Hidden: \\n')\n",
    "    print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "808798cf-0021-4c4d-8405-c720450d4c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      "\n",
      "tensor([[ 0.9684],\n",
      "        [-1.3935]])\n",
      "Output: \n",
      "\n",
      "tensor([[[0.7019],\n",
      "         [0.2180]]], grad_fn=<StackBackward>)\n",
      "Hidden: \n",
      "\n",
      "tensor([[[0.7019],\n",
      "         [0.2180]]], grad_fn=<StackBackward>)\n",
      "---------------------------------------\n",
      "Input: \n",
      "\n",
      "tensor([[-0.0419],\n",
      "        [-0.2666]])\n",
      "Output: \n",
      "\n",
      "tensor([[[0.8859],\n",
      "         [0.7154]]], grad_fn=<StackBackward>)\n",
      "Hidden: \n",
      "\n",
      "tensor([[[0.8859],\n",
      "         [0.7154]]], grad_fn=<StackBackward>)\n",
      "---------------------------------------\n",
      "Input: \n",
      "\n",
      "tensor([[-0.0419],\n",
      "        [-0.2666]])\n",
      "Output: \n",
      "\n",
      "tensor([[[0.7019],\n",
      "         [0.2180]],\n",
      "\n",
      "        [[0.8859],\n",
      "         [0.7154]]], grad_fn=<StackBackward>)\n",
      "Hidden: \n",
      "\n",
      "tensor([[[0.8859],\n",
      "         [0.7154]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "inpt = torch.randn([4])\n",
    "inpt = inpt.view(2, 2, 1)\n",
    "model = lstm(False, inpu_dim = 1)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    param.data.fill_(1)\n",
    "    \n",
    "h = None\n",
    "\n",
    "for t in inpt:\n",
    "    if h == None:\n",
    "        o, (h, c) = model(t.unsqueeze(0))\n",
    "    else:\n",
    "        o, (h, c) = model(t.unsqueeze(0), (h, c))\n",
    "    printer(t, o, h)\n",
    "    print('---------------------------------------')\n",
    "    \n",
    "model = lstm(False, inpu_dim = 1)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    param.data.fill_(1)\n",
    "\n",
    "o, (h, c) = model(inpt)\n",
    "printer(t, o, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a205ac2e-51c7-494b-a790-266bf487d551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.1009]],\n",
      "\n",
      "        [[ 1.6539]],\n",
      "\n",
      "        [[-0.5385]],\n",
      "\n",
      "        [[-1.9041]]])\n",
      "------------------------\n",
      "Input: \n",
      "\n",
      "tensor([[-1.1009]])\n",
      "Output: \n",
      "\n",
      "tensor([[[0.3334]]], grad_fn=<StackBackward>)\n",
      "Hidden: \n",
      "\n",
      "tensor([[[0.3334]]], grad_fn=<StackBackward>)\n",
      "--- Reverse\n",
      "Input: \n",
      "\n",
      "tensor([[-1.9041]])\n",
      "Output: \n",
      "\n",
      "tensor([[[0.0262]]], grad_fn=<StackBackward>)\n",
      "Hidden: \n",
      "\n",
      "tensor([[[0.0262]]], grad_fn=<StackBackward>)\n",
      "------------------------\n",
      "Input: \n",
      "\n",
      "tensor([[1.6539]])\n",
      "Output: \n",
      "\n",
      "tensor([[[0.8852]]], grad_fn=<StackBackward>)\n",
      "Hidden: \n",
      "\n",
      "tensor([[[0.8852]]], grad_fn=<StackBackward>)\n",
      "--- Reverse\n",
      "Input: \n",
      "\n",
      "tensor([[-0.5385]])\n",
      "Output: \n",
      "\n",
      "tensor([[[0.5312]]], grad_fn=<StackBackward>)\n",
      "Hidden: \n",
      "\n",
      "tensor([[[0.5312]]], grad_fn=<StackBackward>)\n",
      "------------------------\n",
      "Input: \n",
      "\n",
      "tensor([[-0.5385]])\n",
      "Output: \n",
      "\n",
      "tensor([[[0.8925]]], grad_fn=<StackBackward>)\n",
      "Hidden: \n",
      "\n",
      "tensor([[[0.8925]]], grad_fn=<StackBackward>)\n",
      "--- Reverse\n",
      "Input: \n",
      "\n",
      "tensor([[1.6539]])\n",
      "Output: \n",
      "\n",
      "tensor([[[0.9273]]], grad_fn=<StackBackward>)\n",
      "Hidden: \n",
      "\n",
      "tensor([[[0.9273]]], grad_fn=<StackBackward>)\n",
      "------------------------\n",
      "Input: \n",
      "\n",
      "tensor([[-1.9041]])\n",
      "Output: \n",
      "\n",
      "tensor([[[0.7107]]], grad_fn=<StackBackward>)\n",
      "Hidden: \n",
      "\n",
      "tensor([[[0.7107]]], grad_fn=<StackBackward>)\n",
      "--- Reverse\n",
      "Input: \n",
      "\n",
      "tensor([[-1.1009]])\n",
      "Output: \n",
      "\n",
      "tensor([[[0.8450]]], grad_fn=<StackBackward>)\n",
      "Hidden: \n",
      "\n",
      "tensor([[[0.8450]]], grad_fn=<StackBackward>)\n",
      "------------------------\n",
      "Input: \n",
      "\n",
      "tensor([[-1.9041]])\n",
      "Output: \n",
      "\n",
      "tensor([[[0.3334, 0.8450]],\n",
      "\n",
      "        [[0.8852, 0.9273]],\n",
      "\n",
      "        [[0.8925, 0.5312]],\n",
      "\n",
      "        [[0.7107, 0.0262]]], grad_fn=<CatBackward>)\n",
      "Hidden: \n",
      "\n",
      "tensor([[[0.7107]],\n",
      "\n",
      "        [[0.8450]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "inpt = torch.randn([4])\n",
    "inpt = inpt.view(4, 1, 1) # Shape (inpt): [seq len, batch size, inp dimension]\n",
    "print(inpt)\n",
    "print(\"------------------------\")\n",
    "\n",
    "model = lstm(False, inpu_dim = 1)\n",
    "for name, param in model.named_parameters():\n",
    "    param.data.fill_(1)\n",
    "h = None\n",
    "\n",
    "inpx = torch.flip(inpt, [0, 1])\n",
    "\n",
    "\n",
    "for t, tx in zip(inpt, inpx):\n",
    "    if h == None:\n",
    "        o, (h, c) = model(t.unsqueeze(0))\n",
    "        ox, (hx, cx) = model(tx.unsqueeze(0))\n",
    "    else:\n",
    "        o, (h, c) = model(t.unsqueeze(0), (h, c))\n",
    "        ox, (hx, cx) = model(tx.unsqueeze(0), (hx, cx))\n",
    "    printer(t, o, h)\n",
    "    print('--- Reverse')\n",
    "    printer(tx, ox, hx)\n",
    "    print(\"------------------------\")\n",
    "    \n",
    "    \n",
    "    \n",
    "model = lstm(True, inpu_dim = 1)\n",
    "for name, param in model.named_parameters():\n",
    "    param.data.fill_(1)\n",
    "\n",
    "o, (h, c) = model(inpt)\n",
    "printer(t, o, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91b6373e-c3ee-41be-a2fe-c4ffca4bf765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0\n",
      "weight_hh_l0\n",
      "bias_ih_l0\n",
      "bias_hh_l0\n"
     ]
    }
   ],
   "source": [
    "for name, param in lstm(False, inpu_size = 1).named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3544628f-aa9b-4398-a386-230cfb8b69e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0\n",
      "weight_hh_l0\n",
      "bias_ih_l0\n",
      "bias_hh_l0\n",
      "weight_ih_l0_reverse\n",
      "weight_hh_l0_reverse\n",
      "bias_ih_l0_reverse\n",
      "bias_hh_l0_reverse\n"
     ]
    }
   ],
   "source": [
    "for name, param in lstm(True, inpu_size = 1).named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58454317-2d88-4ae6-ac1a-9bd660189ca2",
   "metadata": {},
   "source": [
    "Basically, output of LSTM is the cummulative hidden states over all time steps.\n",
    "While hidden state is over t time Step.\n",
    "for Bi-directional, we get forward and backward both in output.\n",
    "We can concatenate it or sum or multiply its just another hyper parameter and then pass it to linear layer to finally predict!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
