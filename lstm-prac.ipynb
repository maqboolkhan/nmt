{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b6979919-5368-481b-b0e6-393bb76c1d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b9c199bf-7a79-4bec-b443-ba7ff28fafe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(inpu_dim, num_layers, bi):\n",
    "    inp_size, hidden_size, num_layers = inpu_dim, 1, num_layers\n",
    "    model = nn.LSTM(inp_size, hidden_size, num_layers, bidirectional=bi)\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        param.data.fill_(1)\n",
    "        \n",
    "    return model\n",
    "    \n",
    "\n",
    "def printer(inpt, o, h):\n",
    "    # [seq len, batch size, inp dimension]\n",
    "    print('\\nInput: ')\n",
    "    print(inpt)\n",
    "    # [seq len, batch size, inp dimension * 2]\n",
    "    print('\\nOutput: ')\n",
    "    print(o)\n",
    "    # [num_layers * 2 , batch size, inp dimension]\n",
    "    print('\\nHidden: ')\n",
    "    print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ef3909e2-b830-4544-9c57-714ed4b4b4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7050]],\n",
      "\n",
      "        [[0.9573]]])\n"
     ]
    }
   ],
   "source": [
    "inpt = torch.randn([2])\n",
    "inpt = inpt.view(2, 1, 1)\n",
    "print(inpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a77f72a-6d41-4528-970b-10dd4383ab3a",
   "metadata": {},
   "source": [
    "### Uni-direction with Single layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f649463e-ae72-4268-bff8-c99af040dac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: \n",
      "tensor([[0.7050]])\n",
      "\n",
      "Output: \n",
      "tensor([[[0.6844]]], grad_fn=<StackBackward>)\n",
      "\n",
      "Hidden: \n",
      "tensor([[[0.6844]]], grad_fn=<StackBackward>)\n",
      "---------------------------------------\n",
      "\n",
      "Input: \n",
      "tensor([[0.9573]])\n",
      "\n",
      "Output: \n",
      "tensor([[[0.9300]]], grad_fn=<StackBackward>)\n",
      "\n",
      "Hidden: \n",
      "tensor([[[0.9300]]], grad_fn=<StackBackward>)\n",
      "---------------------------------------\n",
      "------------- Full batch --------------\n",
      "\n",
      "Input: \n",
      "tensor([[[0.7050]],\n",
      "\n",
      "        [[0.9573]]])\n",
      "\n",
      "Output: \n",
      "tensor([[[0.6844]],\n",
      "\n",
      "        [[0.9300]]], grad_fn=<StackBackward>)\n",
      "\n",
      "Hidden: \n",
      "tensor([[[0.9300]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = lstm(1, 1, False)\n",
    "\n",
    "h = None\n",
    "\n",
    "for t in inpt:\n",
    "    if h == None:\n",
    "        o, (h, c) = model(t.unsqueeze(0))\n",
    "    else:\n",
    "        o, (h, c) = model(t.unsqueeze(0), (h, c))\n",
    "    printer(t, o, h)\n",
    "    print('---------------------------------------')\n",
    "\n",
    "print('------------- Full batch --------------')\n",
    "model = lstm(1, 1, False)\n",
    "\n",
    "o, (h, c) = model(inpt)\n",
    "printer(inpt, o, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d321afe7-0d2f-4b14-8264-f32c1a046cc0",
   "metadata": {},
   "source": [
    "---\n",
    "### Uni-direction with two layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f6e0af86-2412-44ba-9012-336af3184633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: \n",
      "tensor([[0.7050]])\n",
      "\n",
      "Output: \n",
      "tensor([[[0.6828]]], grad_fn=<StackBackward>)\n",
      "\n",
      "Hidden: \n",
      "tensor([[[0.6844]],\n",
      "\n",
      "        [[0.6828]]], grad_fn=<StackBackward>)\n",
      "---------------------------------------\n",
      "\n",
      "Input: \n",
      "tensor([[0.9573]])\n",
      "\n",
      "Output: \n",
      "tensor([[[0.9290]]], grad_fn=<StackBackward>)\n",
      "\n",
      "Hidden: \n",
      "tensor([[[0.9300]],\n",
      "\n",
      "        [[0.9290]]], grad_fn=<StackBackward>)\n",
      "---------------------------------------\n",
      "------------- Full batch --------------\n",
      "\n",
      "Input: \n",
      "tensor([[[0.7050]],\n",
      "\n",
      "        [[0.9573]]])\n",
      "\n",
      "Output: \n",
      "tensor([[[0.6828]],\n",
      "\n",
      "        [[0.9290]]], grad_fn=<StackBackward>)\n",
      "\n",
      "Hidden: \n",
      "tensor([[[0.9300]],\n",
      "\n",
      "        [[0.9290]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "inp_size, num_layers = 1, 2\n",
    "model = lstm(inp_size, num_layers, False)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    param.data.fill_(1)\n",
    "\n",
    "h = None\n",
    "\n",
    "for t in inpt:\n",
    "    if h == None:\n",
    "        o, (h, c) = model(t.unsqueeze(0))\n",
    "    else:\n",
    "        o, (h, c) = model(t.unsqueeze(0), (h, c))\n",
    "    printer(t, o, h)\n",
    "    print('---------------------------------------')\n",
    "\n",
    "print('------------- Full batch --------------')\n",
    "model = lstm(inp_size, num_layers, False)\n",
    "\n",
    "o, (h, c) = model(inpt)\n",
    "printer(inpt, o, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c16b58-8c4e-422f-8ce3-5e4b7b50cb46",
   "metadata": {},
   "source": [
    "---\n",
    "## Analyzing bi-directional LSTM \n",
    "\n",
    "### Single layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d49a40ab-647a-43be-83a1-63edb688e68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: \n",
      "tensor([[0.7050]])\n",
      "\n",
      "Output: \n",
      "tensor([[[0.6844]]], grad_fn=<StackBackward>)\n",
      "\n",
      "Hidden: \n",
      "tensor([[[0.6844]]], grad_fn=<StackBackward>)\n",
      "\n",
      "<<< Reverse\n",
      "\n",
      "Input: \n",
      "tensor([[0.9573]])\n",
      "\n",
      "Output: \n",
      "tensor([[[0.7013]]], grad_fn=<StackBackward>)\n",
      "\n",
      "Hidden: \n",
      "tensor([[[0.7013]]], grad_fn=<StackBackward>)\n",
      "---------------------------------------\n",
      "\n",
      "Input: \n",
      "tensor([[0.9573]])\n",
      "\n",
      "Output: \n",
      "tensor([[[0.9300]]], grad_fn=<StackBackward>)\n",
      "\n",
      "Hidden: \n",
      "tensor([[[0.9300]]], grad_fn=<StackBackward>)\n",
      "\n",
      "<<< Reverse\n",
      "\n",
      "Input: \n",
      "tensor([[0.7050]])\n",
      "\n",
      "Output: \n",
      "tensor([[[0.9239]]], grad_fn=<StackBackward>)\n",
      "\n",
      "Hidden: \n",
      "tensor([[[0.9239]]], grad_fn=<StackBackward>)\n",
      "---------------------------------------\n",
      "------------- Full batch --------------\n",
      "\n",
      "Input: \n",
      "tensor([[[0.7050]],\n",
      "\n",
      "        [[0.9573]]])\n",
      "\n",
      "Output: \n",
      "tensor([[[0.6844, 0.9239]],\n",
      "\n",
      "        [[0.9300, 0.7013]]], grad_fn=<CatBackward>)\n",
      "\n",
      "Hidden: \n",
      "tensor([[[0.9300]],\n",
      "\n",
      "        [[0.9239]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "inp_size = 1\n",
    "num_layers = 1\n",
    "model = lstm(inp_size, num_layers, False)\n",
    "h = None\n",
    "\n",
    "inpx = torch.flip(inpt, [0, 1])\n",
    "\n",
    "\n",
    "for t, tx in zip(inpt, inpx):\n",
    "    if h == None:\n",
    "        o, (h, c) = model(t.unsqueeze(0))\n",
    "        ox, (hx, cx) = model(tx.unsqueeze(0))\n",
    "    else:\n",
    "        o, (h, c) = model(t.unsqueeze(0), (h, c))\n",
    "        ox, (hx, cx) = model(tx.unsqueeze(0), (hx, cx))\n",
    "    printer(t, o, h)\n",
    "    print('\\n<<< Reverse')\n",
    "    printer(tx, ox, hx)\n",
    "    print('---------------------------------------')\n",
    "    \n",
    "print('------------- Full batch --------------')\n",
    "model = lstm(inp_size, num_layers, True)\n",
    "\n",
    "o, (h1, c) = model(inpt)\n",
    "printer(inpt, o, h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8984f8ee-c8cd-4c71-90dd-018dc33bfdfc",
   "metadata": {},
   "source": [
    "### With double layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "caf82223-3e55-4cf3-92b3-06e566331a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: \n",
      "tensor([[[0.7050]],\n",
      "\n",
      "        [[0.9573]]])\n",
      "\n",
      "Output: \n",
      "tensor([[[0.7299, 0.9477]],\n",
      "\n",
      "        [[0.9480, 0.7306]]], grad_fn=<CatBackward>)\n",
      "\n",
      "Hidden: \n",
      "tensor([[[0.9300]],\n",
      "\n",
      "        [[0.9239]],\n",
      "\n",
      "        [[0.9480]],\n",
      "\n",
      "        [[0.9477]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "inp_size = 1\n",
    "num_layers = 2\n",
    "\n",
    "model = lstm(inp_size, num_layers, True)\n",
    "\n",
    "o, (h2, c) = model(inpt)\n",
    "printer(inpt, o, h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76824bec-6d04-472d-9a9e-fe905b95b845",
   "metadata": {},
   "source": [
    "### Accessing output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a892feb8-f384-4fba-afd0-da8b74899569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7299]],\n",
       "\n",
       "        [[0.9480]]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[:, :, :1] # Forward LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fb41d46d-500b-40ae-8408-5bb260421d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9477]],\n",
       "\n",
       "        [[0.7306]]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[:, :, 1:] # Backward LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a04a60-f64d-402c-8ff9-367e2d9ff742",
   "metadata": {},
   "source": [
    "### Accessing hidden layer output from single layered LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0e9b37ad-c027-4de0-9ebe-d1ace3cfeae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9300]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1[-2,:,:] # forward RNN hidden state output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "92078a20-8b93-4f52-8367-fee5397c6f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9239]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1[-1,:,:] # backward RNN hidden state output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa0a729-fab8-43f5-9f87-58d2859336d3",
   "metadata": {},
   "source": [
    "### Accessing hidden layer output from double layered LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "56818e5a-4bf7-4ec4-89bb-edccf8484133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st layer forward: \n",
      " tensor([[0.9300]], grad_fn=<SliceBackward>) \n",
      "1st layer backward: \n",
      " tensor([[0.9239]], grad_fn=<SliceBackward>)\n",
      "\n",
      "2nd layer forward: \n",
      " tensor([[0.9480]], grad_fn=<SliceBackward>) \n",
      "2nd layer backward: \n",
      " tensor([[0.9477]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "num_layers = 2\n",
    "num_directions = 2\n",
    "batch = 1\n",
    "hidden_size = 1\n",
    "\n",
    "first_layer_lstm = h2.view(num_layers, num_directions, batch, hidden_size)[0]\n",
    "second_layer_lstm = h2.view(num_layers, num_directions, batch, hidden_size)[1]\n",
    "\n",
    "print('1st layer forward: \\n', first_layer_lstm[-2,:,:], '\\n1st layer backward: \\n', first_layer_lstm[-1,:,:])\n",
    "print('\\n2nd layer forward: \\n', second_layer_lstm[-2,:,:], '\\n2nd layer backward: \\n', second_layer_lstm[-1,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9762997-c7bb-4258-ae21-57a1c5a75157",
   "metadata": {},
   "source": [
    "### Analyzing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "91b6373e-c3ee-41be-a2fe-c4ffca4bf765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0\n",
      "Parameter containing:\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], requires_grad=True)\n",
      "-----------\n",
      "weight_hh_l0\n",
      "Parameter containing:\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], requires_grad=True)\n",
      "-----------\n",
      "bias_ih_l0\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "-----------\n",
      "bias_hh_l0\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "for name, param in lstm(1, 1, False).named_parameters():\n",
    "    print(name)\n",
    "    print(param)\n",
    "    print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d25c12e2-83ff-4aae-9531-83d9b5d7cc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0\n",
      "Parameter containing:\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], requires_grad=True)\n",
      "-----------\n",
      "weight_hh_l0\n",
      "Parameter containing:\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], requires_grad=True)\n",
      "-----------\n",
      "bias_ih_l0\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "-----------\n",
      "bias_hh_l0\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "-----------\n",
      "weight_ih_l1\n",
      "Parameter containing:\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], requires_grad=True)\n",
      "-----------\n",
      "weight_hh_l1\n",
      "Parameter containing:\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], requires_grad=True)\n",
      "-----------\n",
      "bias_ih_l1\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "-----------\n",
      "bias_hh_l1\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "for name, param in lstm(1, 2, False).named_parameters():\n",
    "    print(name)\n",
    "    print(param)\n",
    "    print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3544628f-aa9b-4398-a386-230cfb8b69e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0\n",
      "Parameter containing:\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], requires_grad=True)\n",
      "-----------\n",
      "weight_hh_l0\n",
      "Parameter containing:\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], requires_grad=True)\n",
      "-----------\n",
      "bias_ih_l0\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "-----------\n",
      "bias_hh_l0\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "-----------\n",
      "weight_ih_l0_reverse\n",
      "Parameter containing:\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], requires_grad=True)\n",
      "-----------\n",
      "weight_hh_l0_reverse\n",
      "Parameter containing:\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], requires_grad=True)\n",
      "-----------\n",
      "bias_ih_l0_reverse\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "-----------\n",
      "bias_hh_l0_reverse\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "for name, param in lstm(1, 1, True).named_parameters():\n",
    "    print(name)\n",
    "    print(param)\n",
    "    print('-----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58454317-2d88-4ae6-ac1a-9bd660189ca2",
   "metadata": {},
   "source": [
    "Basically, output of LSTM is the cummulative hidden states over all time steps.\n",
    "While hidden state is over t time Step.\n",
    "for Bi-directional, we get forward and backward both in output.\n",
    "We can concatenate it or sum or multiply or pass it to linear layer. its just another hyper parameter and then pass it to linear layer to finally predict!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a44f015-0090-47dd-a543-f18400c427e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 4])\n",
      "tensor([[[0.8673, 0.1860, 0.2513, 0.9623],\n",
      "         [0.4967, 0.1907, 0.2801, 0.8897]],\n",
      "\n",
      "        [[0.1326, 0.7849, 0.9479, 0.7799],\n",
      "         [0.3995, 0.8238, 0.8698, 0.9360]],\n",
      "\n",
      "        [[0.5219, 0.0967, 0.4878, 0.4901],\n",
      "         [0.7813, 0.6874, 0.4124, 0.4624]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8673, 0.1860, 0.2513, 0.9623],\n",
       "         [0.1326, 0.7849, 0.9479, 0.7799],\n",
       "         [0.5219, 0.0967, 0.4878, 0.4901]],\n",
       "\n",
       "        [[0.4967, 0.1907, 0.2801, 0.8897],\n",
       "         [0.3995, 0.8238, 0.8698, 0.9360],\n",
       "         [0.7813, 0.6874, 0.4124, 0.4624]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[src len, batch size, enc hid dim * 2]\n",
    "import torch\n",
    "enc = torch.rand([3, 2, 2*2])\n",
    "print(enc.shape)\n",
    "print(enc)\n",
    "enc.permute(1, 0, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
