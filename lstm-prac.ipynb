{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6979919-5368-481b-b0e6-393bb76c1d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b9c199bf-7a79-4bec-b443-ba7ff28fafe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(bi, inpu_dim):\n",
    "    inp_size, hidden_size, num_layers = inpu_dim, 1, 1\n",
    "    return nn.LSTM(inp_size, hidden_size, num_layers, bidirectional=bi)\n",
    "    \n",
    "\n",
    "def printer(inpt, o, h):\n",
    "    # [seq len, batch size, inp dimension]\n",
    "    print('Input: \\n')\n",
    "    print(inpt)\n",
    "    # [seq len, batch size, inp dimension * 2]\n",
    "    print('Output: \\n')\n",
    "    print(o)\n",
    "    # [num_layers * 2 , batch size, inp dimension]\n",
    "    print('Hidden: \\n')\n",
    "    print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "808798cf-0021-4c4d-8405-c720450d4c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      "\n",
      "tensor([[ 0.9684],\n",
      "        [-1.3935]])\n",
      "Output: \n",
      "\n",
      "tensor([[[0.7019],\n",
      "         [0.2180]]], grad_fn=<StackBackward>)\n",
      "Hidden: \n",
      "\n",
      "tensor([[[0.7019],\n",
      "         [0.2180]]], grad_fn=<StackBackward>)\n",
      "---------------------------------------\n",
      "Input: \n",
      "\n",
      "tensor([[-0.0419],\n",
      "        [-0.2666]])\n",
      "Output: \n",
      "\n",
      "tensor([[[0.8859],\n",
      "         [0.7154]]], grad_fn=<StackBackward>)\n",
      "Hidden: \n",
      "\n",
      "tensor([[[0.8859],\n",
      "         [0.7154]]], grad_fn=<StackBackward>)\n",
      "---------------------------------------\n",
      "Input: \n",
      "\n",
      "tensor([[-0.0419],\n",
      "        [-0.2666]])\n",
      "Output: \n",
      "\n",
      "tensor([[[0.7019],\n",
      "         [0.2180]],\n",
      "\n",
      "        [[0.8859],\n",
      "         [0.7154]]], grad_fn=<StackBackward>)\n",
      "Hidden: \n",
      "\n",
      "tensor([[[0.8859],\n",
      "         [0.7154]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "inpt = torch.randn([4])\n",
    "inpt = inpt.view(2, 2, 1)\n",
    "model = lstm(False, inpu_dim = 1)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    param.data.fill_(1)\n",
    "    \n",
    "h = None\n",
    "\n",
    "for t in inpt:\n",
    "    if h == None:\n",
    "        o, (h, c) = model(t.unsqueeze(0))\n",
    "    else:\n",
    "        o, (h, c) = model(t.unsqueeze(0), (h, c))\n",
    "    printer(t, o, h)\n",
    "    print('---------------------------------------')\n",
    "    \n",
    "model = lstm(False, inpu_dim = 1)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    param.data.fill_(1)\n",
    "\n",
    "o, (h, c) = model(inpt)\n",
    "printer(t, o, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a205ac2e-51c7-494b-a790-266bf487d551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1617,  0.7615],\n",
      "         [ 0.8497, -1.3913]],\n",
      "\n",
      "        [[ 1.5245,  0.6360],\n",
      "         [-0.2786, -0.6527]]])\n",
      "------------------------\n",
      "Input: \n",
      "\n",
      "tensor([[-0.1617,  0.7615],\n",
      "        [ 0.8497, -1.3913]])\n",
      "Output: \n",
      "\n",
      "tensor([[[0.6760],\n",
      "         [0.5045]]], grad_fn=<StackBackward>)\n",
      "Hidden: \n",
      "\n",
      "tensor([[[0.6760],\n",
      "         [0.5045]]], grad_fn=<StackBackward>)\n",
      "--- Reverse\n",
      "Input: \n",
      "\n",
      "tensor([[-0.2786, -0.6527],\n",
      "        [ 1.5245,  0.6360]])\n",
      "Output: \n",
      "\n",
      "tensor([[[0.3930],\n",
      "         [0.7433]]], grad_fn=<StackBackward>)\n",
      "Hidden: \n",
      "\n",
      "tensor([[[0.3930],\n",
      "         [0.7433]]], grad_fn=<StackBackward>)\n",
      "------------------------\n",
      "Input: \n",
      "\n",
      "tensor([[ 1.5245,  0.6360],\n",
      "        [-0.2786, -0.6527]])\n",
      "Output: \n",
      "\n",
      "tensor([[[0.9492],\n",
      "         [0.7264]]], grad_fn=<StackBackward>)\n",
      "Hidden: \n",
      "\n",
      "tensor([[[0.9492],\n",
      "         [0.7264]]], grad_fn=<StackBackward>)\n",
      "--- Reverse\n",
      "Input: \n",
      "\n",
      "tensor([[ 0.8497, -1.3913],\n",
      "        [-0.1617,  0.7615]])\n",
      "Output: \n",
      "\n",
      "tensor([[[0.7513],\n",
      "         [0.9248]]], grad_fn=<StackBackward>)\n",
      "Hidden: \n",
      "\n",
      "tensor([[[0.7513],\n",
      "         [0.9248]]], grad_fn=<StackBackward>)\n",
      "------------------------\n",
      "Input: \n",
      "\n",
      "tensor([[ 1.5245,  0.6360],\n",
      "        [-0.2786, -0.6527]])\n",
      "Output: \n",
      "\n",
      "tensor([[[0.6760, 0.9248],\n",
      "         [0.5045, 0.7513]],\n",
      "\n",
      "        [[0.9492, 0.7433],\n",
      "         [0.7264, 0.3930]]], grad_fn=<CatBackward>)\n",
      "Hidden: \n",
      "\n",
      "tensor([[[0.9492],\n",
      "         [0.7264]],\n",
      "\n",
      "        [[0.9248],\n",
      "         [0.7513]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "inpt = torch.randn([8])\n",
    "inpt = inpt.view(2, 2, 2) # Shape (inpt): [seq len, batch size, inp dimension]\n",
    "print(inpt)\n",
    "print(\"------------------------\")\n",
    "\n",
    "model = lstm(False, inpu_dim = 2)\n",
    "for name, param in model.named_parameters():\n",
    "    param.data.fill_(1)\n",
    "h = None\n",
    "\n",
    "inpx = torch.flip(inpt, [0, 1])\n",
    "\n",
    "\n",
    "for t, tx in zip(inpt, inpx):\n",
    "    if h == None:\n",
    "        o, (h, c) = model(t.unsqueeze(0))\n",
    "        ox, (hx, cx) = model(tx.unsqueeze(0))\n",
    "    else:\n",
    "        o, (h, c) = model(t.unsqueeze(0), (h, c))\n",
    "        ox, (hx, cx) = model(tx.unsqueeze(0), (hx, cx))\n",
    "    printer(t, o, h)\n",
    "    print('--- Reverse')\n",
    "    printer(tx, ox, hx)\n",
    "    print(\"------------------------\")\n",
    "    \n",
    "    \n",
    "    \n",
    "model = lstm(True, inpu_dim = 2)\n",
    "for name, param in model.named_parameters():\n",
    "    param.data.fill_(1)\n",
    "\n",
    "o, (h, c) = model(inpt)\n",
    "printer(t, o, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e9b37ad-c027-4de0-9ebe-d1ace3cfeae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9492],\n",
       "        [0.7264]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h[-2,:,:] # forward RNN hidden state output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92078a20-8b93-4f52-8367-fee5397c6f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9248],\n",
       "        [0.7513]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h[-1,:,:] # forward RNN hidden state output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91b6373e-c3ee-41be-a2fe-c4ffca4bf765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0\n",
      "weight_hh_l0\n",
      "bias_ih_l0\n",
      "bias_hh_l0\n"
     ]
    }
   ],
   "source": [
    "for name, param in lstm(False, inpu_size = 1).named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3544628f-aa9b-4398-a386-230cfb8b69e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0\n",
      "weight_hh_l0\n",
      "bias_ih_l0\n",
      "bias_hh_l0\n",
      "weight_ih_l0_reverse\n",
      "weight_hh_l0_reverse\n",
      "bias_ih_l0_reverse\n",
      "bias_hh_l0_reverse\n"
     ]
    }
   ],
   "source": [
    "for name, param in lstm(True, inpu_size = 1).named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58454317-2d88-4ae6-ac1a-9bd660189ca2",
   "metadata": {},
   "source": [
    "Basically, output of LSTM is the cummulative hidden states over all time steps.\n",
    "While hidden state is over t time Step.\n",
    "for Bi-directional, we get forward and backward both in output.\n",
    "We can concatenate it or sum or multiply its just another hyper parameter and then pass it to linear layer to finally predict!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
